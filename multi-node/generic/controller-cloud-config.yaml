#cloud-config

coreos:
  update:
    reboot-strategy: "off"

  flannel:
    interface: $private_ipv4
    etcd_endpoints: {{ETCD_ENDPOINTS}}

  units:
  - name: bootstrap.service
    command: start
    content: |
      [Service]
      ExecStart=/bin/bash -e /tmp/bootstrap.sh
      Type=oneshot

      # List of etcd servers (http://ip:port), comma separated
      Environment=ETCD_ENDPOINTS={{ETCD_ENDPOINTS}}

      # The CIDR network to use for pod IPs.
      # Each pod launched in the cluster will be assigned an IP out of this range.
      # Each node will be configured such that these IPs will be routable using the flannel overlay network.
      #Environment=POD_NETWORK=10.2.0.0/16

      # The CIDR network to use for service cluster IPs.
      # Each service will be assigned a cluster IP out of this range.
      # This must not overlap with any IP ranges assigned to the POD_NETWORK, or other existing network infrastructure.
      # Routing to these IPs is handled by a proxy service local to each node, and are not required to be routable between nodes.
      #Environment=SERVICE_IP_RANGE=10.3.0.0/24

      # The IP address of the Kubernetes API Service
      # If the SERVICE_IP_RANGE is changed above, this must be set to the first IP in that range.
      #Environment=K8S_SERVICE_IP=10.3.0.1

      # The IP address of the cluster DNS service.
      # This IP must be in the range of the SERVICE_IP_RANGE and cannot be the first IP in the range.
      # This same IP must be configured on all worker nodes to enable DNS service discovery.
      #Environment=DNS_SERVICE_IP=10.3.0.10

      # The above settings can optionally be overridden using an environment file:
      EnvironmentFile=-/tmp/kube-bootstrap-env

write_files:
- path: /tmp/bootstrap.sh
  content: |
    /bin/bash /tmp/controller.sh init

    KEY_FILE="/etc/kubernetes/service-account-private-key.pem"
    echo "Waiting for ${KEY_FILE} to exist..."
    while [ ! -e "${KEY_FILE}" ]; do
      sleep 5
    done

    /bin/bash /tmp/controller.sh start

- path: /tmp/controller.sh
  # --- CONTENT AUTOGENERATED ---
  content: |
    #!/bin/bash -e

    function usage {
        echo "USAGE: $0 <command>"
        echo "Commands:"
        echo -e "\tinit \tInitialize control node services"
        echo -e "\tstart \tStart control node services"
    }

    if [ -z $1 ]; then
        usage
        exit 1
    fi

    CMD=$1

    # Sanity check kubelet is available in image (missing will exit with set -e)
    which kubelet
    K8S_VER=$(kubelet --version | awk '{print $2}')

    function init_config {
        local REQUIRED=('ADVERTISE_IP' 'POD_NETWORK' 'ETCD_ENDPOINTS' 'SERVICE_IP_RANGE' 'K8S_SERVICE_IP' 'DNS_SERVICE_IP' )

        if [ -z $ADVERTISE_IP ]; then
            export ADVERTISE_IP=$(awk -F= '/COREOS_PUBLIC_IPV4/ {print $2}' /etc/environment)
        fi
        if [ -z $POD_NETWORK ]; then
            export POD_NETWORK="10.2.0.0/16"
        fi
        if [ -z $ETCD_ENDPOINTS ]; then
            export ETCD_ENDPOINTS="http://127.0.0.1:2379"
        fi
        if [ -z $SERVICE_IP_RANGE ]; then
            export SERVICE_IP_RANGE="10.3.0.0/24"
        fi
        if [ -z $K8S_SERVICE_IP ]; then
            export K8S_SERVICE_IP="10.3.0.1"
        fi
        if [ -z $DNS_SERVICE_IP ]; then
            export DNS_SERVICE_IP="10.3.0.10"
        fi
        for REQ in "${REQUIRED[@]}"; do
            if [ -z "$(eval echo \$$REQ)" ]; then
                echo "Missing required config value: ${REQ}"
                exit 1
            fi
        done

        # For use in single-node deployments
        if [ "$REGISTER_NODE" != "true" ]; then
            export REGISTER_NODE="false"
        fi
    }

    function init_flannel {
        echo "Waiting for etcd..."
        while true
        do
            IFS=',' read -ra ES <<< "$ETCD_ENDPOINTS"
            for ETCD in "${ES[@]}"; do
                echo "Trying: $ETCD"
                if [ -n "$(curl --silent "$ETCD/v2/machines")" ]; then
                    local ACTIVE_ETCD=$ETCD
                    break
                fi
                sleep 1
            done
            if [ -n "$ACTIVE_ETCD" ]; then
                break
            fi
        done
        RES=$(curl --silent -X PUT -d "value={\"Network\":\"$POD_NETWORK\"}" "$ACTIVE_ETCD/v2/keys/coreos.com/network/config?prevExist=false")
        if [ -z "$(echo $RES | grep '"action":"create"')" ] && [ -z "$(echo $RES | grep 'Key already exists')" ]; then
            echo "Unexpected error configuring flannel pod network: $RES"
        fi
    }

    function init_docker {
        local TEMPLATE=/etc/systemd/system/docker.service.d/40-flannel.conf
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    [Unit]
    Requires=flanneld.service
    After=flanneld.service
    EOF
        }

        # reload now before docker commands are run in later
        # init steps or dockerd will start before flanneld
        systemctl daemon-reload
    }

    function init_kubectl {
        [ -f /opt/bin/kubectl ] || {
            mkdir -p /opt/bin
            curl --silent -o /opt/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/$K8S_VER/bin/linux/amd64/kubectl
            chown core:core /opt/bin/kubectl
            chmod +x /opt/bin/kubectl
        }
    }

    function init_templates {
        local TEMPLATE=/etc/systemd/system/kubelet.service
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    [Service]
    ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
    ExecStart=/usr/bin/kubelet \
      --api_servers=http://127.0.0.1:8080 \
      --register-node=${REGISTER_NODE} \
      --allow-privileged=true \
      --config=/etc/kubernetes/manifests \
      --hostname-override=${ADVERTISE_IP} \
      --cluster_dns=${DNS_SERVICE_IP} \
      --cluster_domain=cluster.local \
      --cadvisor-port=0
    Restart=always
    RestartSec=10

    [Install]
    WantedBy=multi-user.target
    EOF
        }

        local TEMPLATE=/etc/kubernetes/manifests/kube-proxy.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Pod
    metadata:
      name: kube-proxy
      namespace: kube-system
    spec:
      hostNetwork: true
      containers:
      - name: kube-proxy
        image: gcr.io/google_containers/hyperkube:$K8S_VER
        command:
        - /hyperkube
        - proxy
        - --master=http://127.0.0.1:8080
        securityContext:
          privileged: true
        volumeMounts:
          - mountPath: /etc/ssl/certs
            name: "ssl-certs"
      volumes:
        - name: "ssl-certs"
          hostPath:
            path: "/usr/share/ca-certificates"
    EOF
        }

        local TEMPLATE=/srv/kubernetes/manifests/kube-system.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Namespace
    metadata:
      name: kube-system
    EOF
        }

        local TEMPLATE=/etc/kubernetes/manifests/kube-apiserver.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Pod
    metadata:
      name: kube-apiserver
      namespace: kube-system
    spec:
      hostNetwork: true
      containers:
      - name: kube-apiserver
        image: gcr.io/google_containers/hyperkube:$K8S_VER
        command:
        - /hyperkube
        - apiserver
        - --bind-address=0.0.0.0
        - --etcd_servers=${ETCD_ENDPOINTS}
        - --allow-privileged=true
        - --service-cluster-ip-range=${SERVICE_IP_RANGE}
        - --secure_port=443
        - --advertise-address=${ADVERTISE_IP}
        - --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota
        ports:
        - containerPort: 443
          hostPort: 443
          name: https
        - containerPort: 7080
          hostPort: 7080
          name: http
        - containerPort: 8080
          hostPort: 8080
          name: local
        volumeMounts:
        - mountPath: /etc/ssl
          name: etcssl
          readOnly: true
        - mountPath: /var/ssl
          name: varssl
          readOnly: true
        - mountPath: /etc/openssl
          name: etcopenssl
          readOnly: true
        - mountPath: /etc/pki/tls
          name: etcpkitls
          readOnly: true
      volumes:
      - hostPath:
          path: /etc/ssl
        name: etcssl
      - hostPath:
          path: /var/ssl
        name: varssl
      - hostPath:
          path: /etc/openssl
        name: etcopenssl
      - hostPath:
          path: /etc/pki/tls
        name: etcpkitls
    EOF
        }

        local TEMPLATE=/etc/kubernetes/manifests/kube-podmaster.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Pod
    metadata:
      name: kube-podmaster
      namespace: kube-system
    spec:
      hostNetwork: true
      containers:
      - name: scheduler-elector
        image: gcr.io/google_containers/podmaster:1.1
        command:
        - /podmaster
        - --etcd-servers=${ETCD_ENDPOINTS}
        - --key=scheduler
        - --whoami=${ADVERTISE_IP}
        - --source-file=/src/manifests/kube-scheduler.yaml
        - --dest-file=/dst/manifests/kube-scheduler.yaml
        volumeMounts:
        - mountPath: /src/manifests
          name: manifest-src
          readOnly: true
        - mountPath: /dst/manifests
          name: manifest-dst
      - name: controller-manager-elector
        image: gcr.io/google_containers/podmaster:1.1
        command:
        - /podmaster
        - --etcd-servers=${ETCD_ENDPOINTS}
        - --key=controller
        - --whoami=${ADVERTISE_IP}
        - --source-file=/src/manifests/kube-controller-manager.yaml
        - --dest-file=/dst/manifests/kube-controller-manager.yaml
        terminationMessagePath: /dev/termination-log
        volumeMounts:
        - mountPath: /src/manifests
          name: manifest-src
          readOnly: true
        - mountPath: /dst/manifests
          name: manifest-dst
      volumes:
      - hostPath:
          path: /srv/kubernetes/manifests
        name: manifest-src
      - hostPath:
          path: /etc/kubernetes/manifests
        name: manifest-dst
    EOF
        }

        local TEMPLATE=/srv/kubernetes/manifests/kube-controller-manager.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Pod
    metadata:
      name: kube-controller-manager
      namespace: kube-system
    spec:
      containers:
      - name: kube-controller-manager
        image: gcr.io/google_containers/hyperkube:$K8S_VER
        command:
        - /hyperkube
        - controller-manager
        - --master=http://127.0.0.1:8080
        - --service-account-private-key-file=/etc/kubernetes/service-account-private-key.pem
        livenessProbe:
          httpGet:
            host: 127.0.0.1
            path: /healthz
            port: 10252
          initialDelaySeconds: 15
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /etc/ssl
          name: etcssl
          readOnly: true
        - mountPath: /var/ssl
          name: varssl
          readOnly: true
        - mountPath: /etc/openssl
          name: etcopenssl
          readOnly: true
        - mountPath: /etc/pki/tls
          name: etcpkitls
          readOnly: true
        - mountPath: /etc/kubernetes/service-account-private-key.pem
          name: service-account-private-key
          readOnly: true
      hostNetwork: true
      volumes:
      - hostPath:
          path: /etc/ssl
        name: etcssl
      - hostPath:
          path: /var/ssl
        name: varssl
      - hostPath:
          path: /etc/openssl
        name: etcopenssl
      - hostPath:
          path: /etc/pki/tls
        name: etcpkitls
      - hostPath:
          path: /etc/kubernetes/service-account-private-key.pem
        name: service-account-private-key
    EOF
        }

        local TEMPLATE=/srv/kubernetes/manifests/kube-scheduler.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Pod
    metadata:
      name: kube-scheduler
      namespace: kube-system
    spec:
      hostNetwork: true
      containers:
      - name: kube-scheduler
        image: gcr.io/google_containers/hyperkube:$K8S_VER
        command:
        - /hyperkube
        - scheduler
        - --master=http://127.0.0.1:8080
        livenessProbe:
          httpGet:
            host: 127.0.0.1
            path: /healthz
            port: 10251
          initialDelaySeconds: 15
          timeoutSeconds: 1
    EOF
        }

        local DNS_KUBECONFIG="
    apiVersion: v1
    kind: Config
    clusters:
    - name: default
      cluster:
         server: https://$K8S_SERVICE_IP
         insecure-skip-tls-verify: true
    contexts:
    - context:
        cluster: default
        namespace: kube-system
      name: dns-context
    current-context: dns-context"

        local TEMPLATE=/srv/kubernetes/manifests/kube-dns.yaml
        [ -f $TEMPLATE ] || {
            echo "TEMPLATE: $TEMPLATE"
            mkdir -p $(dirname $TEMPLATE)
            cat << EOF > $TEMPLATE
    apiVersion: v1
    kind: Secret
    metadata:
      name: dns-kubeconfig
      namespace: kube-system
    data:
      kubeconfig: $(echo "$DNS_KUBECONFIG" | base64 --wrap=0)

    ---

    apiVersion: v1
    kind: ReplicationController
    metadata:
      name: kube-dns-v8
      namespace: kube-system
      labels:
        k8s-app: kube-dns
        version: v8
        kubernetes.io/cluster-service: "true"
    spec:
      replicas: 1
      selector:
        k8s-app: kube-dns
        version: v8
      template:
        metadata:
          labels:
            k8s-app: kube-dns
            version: v8
            kubernetes.io/cluster-service: "true"
        spec:
          containers:
          - name: etcd
            image: gcr.io/google_containers/etcd:2.0.9
            resources:
              limits:
                cpu: 100m
                memory: 50Mi
            command:
            - /usr/local/bin/etcd
            - -data-dir
            - /var/etcd/data
            - -listen-client-urls
            - http://127.0.0.1:2379,http://127.0.0.1:4001
            - -advertise-client-urls
            - http://127.0.0.1:2379,http://127.0.0.1:4001
            - -initial-cluster-token
            - skydns-etcd
            volumeMounts:
            - name: etcd-storage
              mountPath: /var/etcd/data
          - name: kube2sky
            image: gcr.io/google_containers/kube2sky:1.11
            resources:
              limits:
                cpu: 100m
                memory: 50Mi
            args:
            # command = "/kube2sky"
            - -domain=cluster.local
            - --kubecfg_file=/config/kubeconfig
            volumeMounts:
            - name: sslcerts
              mountPath: /etc/ssl/certs/ca-certificates.crt
            - name: kubeconfig
              mountPath: /config
              readOnly: true
          - name: skydns
            image: gcr.io/google_containers/skydns:2015-03-11-001
            resources:
              limits:
                cpu: 100m
                memory: 50Mi
            args:
            # command = "/skydns"
            - -machines=http://localhost:4001
            - -addr=0.0.0.0:53
            - -domain=cluster.local.
            ports:
            - containerPort: 53
              name: dns
              protocol: UDP
            - containerPort: 53
              name: dns-tcp
              protocol: TCP
            livenessProbe:
              httpGet:
                path: /healthz
                port: 8080
                scheme: HTTP
              initialDelaySeconds: 30
              timeoutSeconds: 5
          - name: healthz
            image: gcr.io/google_containers/exechealthz:1.0
            resources:
              limits:
                cpu: 10m
                memory: 20Mi
            args:
            - -cmd=nslookup kubernetes.default.svc.cluster.local localhost >/dev/null
            - -port=8080
            ports:
            - containerPort: 8080
              protocol: TCP
          volumes:
          - name: etcd-storage
            emptyDir: {}
          - name: sslcerts
            hostPath:
              path: /etc/ssl/certs/ca-certificates.crt
          - name: kubeconfig
            secret:
              secretName: dns-kubeconfig
          dnsPolicy: Default  # Don't use cluster DNS.

    ---

    apiVersion: v1
    kind: Service
    metadata:
      name: kube-dns
      namespace: kube-system
      labels:
        k8s-app: kube-dns
        kubernetes.io/name: "KubeDNS"
        kubernetes.io/cluster-service: "true"
    spec:
      selector:
        k8s-app: kube-dns
      clusterIP: $DNS_SERVICE_IP
      ports:
        - protocol: UDP
          name: dns
          port: 53
        - protocol: TCP
          name: dns-tcp
          port: 53
    EOF
        }

    }

    function start_addons {
        echo "Waiting for Kubernetes API..."
        until curl --silent "http://127.0.0.1:8080/version"
        do
            sleep 5
        done
        echo
        echo "K8S: kube-system namespace"
        /opt/bin/kubectl create -f /srv/kubernetes/manifests/kube-system.yaml
        echo "K8S: DNS addon"
        /opt/bin/kubectl create -f /srv/kubernetes/manifests/kube-dns.yaml
    }

    if [ "$CMD" == "init" ]; then
        echo "Starting initialization"
        init_config
        init_flannel
        init_docker
        init_kubectl
        init_templates
        echo "Initialization complete"
        exit 0
    fi

    if [ "$CMD" == "start" ]; then
        echo "Starting services"
        systemctl daemon-reload
        systemctl enable kubelet; systemctl start kubelet
        start_addons
        echo "Service start complete"
        exit 0
    fi

    usage
    exit 1
