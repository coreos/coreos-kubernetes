#cloud-config
coreos:
  update:
    reboot-strategy: "off"
  flannel:
    interface: $private_ipv4
    etcd_endpoints: {{ .ETCDEndpoints }}
  etcd2:
    name: controller
    advertise-client-urls: http://$private_ipv4:2379
    initial-advertise-peer-urls: http://$private_ipv4:2380
    listen-client-urls: http://0.0.0.0:2379
    listen-peer-urls: http://0.0.0.0:2380
    initial-cluster: controller=http://$private_ipv4:2380
  units:
    - name: etcd2.service
      command: start

    - name: docker.service
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service

    - name: flanneld.service
      drop-ins:
        - name: 10-etcd.conf
          content: |
            [Service]
            ExecStartPre=/usr/bin/curl --silent -X PUT -d \
            "value={\"Network\" : \"{{.PodCIDR}}\", \"Backend\" : {\"Type\" : \"vxlan\"}}" \
            http://localhost:2379/v2/keys/coreos.com/network/config?prevExist=false
    - name: kubelet.service
      command: start
      enable: true
      content: |
        [Service]
        Environment=KUBELET_VERSION={{.K8sVer}}
        Environment=KUBELET_ACI={{.HyperkubeImageRepo}}
        Environment="RKT_OPTS=--volume dns,kind=host,source=/etc/resolv.conf --mount volume=dns,target=/etc/resolv.conf"
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
        --api-servers=http://localhost:8080 \
        --register-schedulable=false \
        --allow-privileged=true \
        --config=/etc/kubernetes/manifests \
        --cluster_dns={{.DNSServiceIP}} \
        --cluster_domain=cluster.local \
        --cloud-provider=aws
        Restart=always
        RestartSec=10

        [Install]
        WantedBy=multi-user.target

{{ if .UseCalico }}
    - name: calico-node.service
      command: start
      content: |
        [Unit]
        Description=Calico per-host agent
        Requires=network-online.target
        After=network-online.target

        [Service]
        Slice=machine.slice
        Environment=CALICO_DISABLE_FILE_LOGGING=true
        Environment=HOSTNAME=$private_ipv4
        Environment=IP=$private_ipv4
        Environment=FELIX_FELIXHOSTNAME=$private_ipv4
        Environment=CALICO_NETWORKING=false
        Environment=NO_DEFAULT_POOLS=true
        Environment=ETCD_ENDPOINTS={{ .ETCDEndpoints }}
        ExecStart=/usr/bin/rkt run --inherit-env --stage1-from-dir=stage1-fly.aci \
        --volume=modules,kind=host,source=/lib/modules,readOnly=false \
        --mount=volume=modules,target=/lib/modules \
        --trust-keys-from-https quay.io/calico/node:v0.19.0
        KillMode=mixed
        Restart=always
        TimeoutStartSec=0

        [Install]
        WantedBy=multi-user.target
{{ end }}

    - name: decrypt-tls-assets.service
      enable: true
      content: |
        [Unit]
        Description=decrypt kubelet tls assets using amazon kms
        Before=kubelet.service
        After=docker.service
        Requires=docker.service

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/opt/bin/decrypt-tls-assets

        [Install]
        RequiredBy=kubelet.service

    - name: install-kube-system.service
      command: start
      content: |
        [Unit]
        Requires=kubelet.service docker.service
        After=kubelet.service docker.service

        [Service]
        Type=simple
        StartLimitInterval=0
        Restart=on-failure
        ExecStartPre=/usr/bin/curl http://127.0.0.1:8080/version
        ExecStart=/opt/bin/install-kube-system

{{ if .UseCalico }}
    - name: install-calico-system.service
      command: start
      content: |
        [Unit]
        Requires=kubelet.service docker.service
        After=kubelet.service docker.service

        [Service]
        Type=simple
        StartLimitInterval=0
        Restart=on-failure
        ExecStartPre=/usr/bin/curl http://127.0.0.1:8080/version
        ExecStart=/opt/bin/install-calico-system
{{ end }}

write_files:
  - path: /opt/bin/install-kube-system
    permissions: 0700
    owner: root:root
    content: |
      #!/bin/bash -e
      /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
      -d @"/srv/kubernetes/manifests/kube-dns-rc.json" \
      "http://127.0.0.1:8080/api/v1/namespaces/kube-system/replicationcontrollers"

      /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
      -d @"/srv/kubernetes/manifests/kube-dashboard-rc.json" \
      "http://127.0.0.1:8080/api/v1/namespaces/kube-system/replicationcontrollers"

      /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
      -d @"/srv/kubernetes/manifests/heapster-de.json" \
      "http://127.0.0.1:8080/apis/extensions/v1beta1/namespaces/kube-system/deployments"

      for manifest in {kube-dns,heapster,kube-dashboard}-svc.json;do
          /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
          -d @"/srv/kubernetes/manifests/$manifest" \
          "http://127.0.0.1:8080/api/v1/namespaces/kube-system/services"
      done

{{ if .UseCalico }}
  - path: /opt/bin/install-calico-system
    permissions: 0700
    owner: root:root
    content: |
      #!/bin/bash -e
      /usr/bin/curl -H "Content-Type: application/json" -XPOST -d @"/srv/kubernetes/manifests/calico-system.json" "http://127.0.0.1:8080/api/v1/namespaces"

      /usr/bin/cp /srv/kubernetes/manifests/calico-policy-controller.yaml /etc/kubernetes/manifests
{{ end }}

  - path: /opt/bin/decrypt-tls-assets
    owner: root:root
    permissions: 0700
    content: |
      #!/bin/bash -e

      for encKey in $(find /etc/kubernetes/ssl/*.pem.enc);do
        tmpPath="/tmp/$(basename $encKey).tmp"
        docker run --rm -v /etc/kubernetes/ssl:/etc/kubernetes/ssl --rm quay.io/coreos/awscli aws --region {{.Region}} kms decrypt --ciphertext-blob fileb://$encKey --output text --query Plaintext | base64 --decode > $tmpPath
        mv  $tmpPath /etc/kubernetes/ssl/$(basename $encKey .enc)
      done

  - path: /etc/kubernetes/manifests/kube-proxy.yaml
    content: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-proxy
          namespace: kube-system
        spec:
          hostNetwork: true
          containers:
          - name: kube-proxy
            image: {{.HyperkubeImageRepo}}:{{.K8sVer}}
            command:
            - /hyperkube
            - proxy
            - --master=http://127.0.0.1:8080
            securityContext:
              privileged: true
            volumeMounts:
            - mountPath: /etc/ssl/certs
              name: ssl-certs-host
              readOnly: true
          volumes:
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-apiserver.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: {{.HyperkubeImageRepo}}:{{.K8sVer}}
          command:
          - /hyperkube
          - apiserver
          - --bind-address=0.0.0.0
          - --etcd-servers=http://localhost:2379
          - --allow-privileged=true
          - --service-cluster-ip-range={{.ServiceCIDR}}
          - --secure-port=443
          - --advertise-address=$private_ipv4
          - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota
          - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --runtime-config=extensions/v1beta1/networkpolicies=true
          - --cloud-provider=aws
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              port: 8080
              path: /healthz
            initialDelaySeconds: 15
            timeoutSeconds: 15
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        containers:
        - name: kube-controller-manager
          image: {{.HyperkubeImageRepo}}:{{.K8sVer}}
          command:
          - /hyperkube
          - controller-manager
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          - --cloud-provider=aws
          resources:
            requests:
              cpu: 200m
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 15
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        hostNetwork: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-scheduler.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: {{.HyperkubeImageRepo}}:{{.K8sVer}}
          command:
          - /hyperkube
          - scheduler
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          resources:
            requests:
              cpu: 100m
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 15

{{ if .UseCalico }}
  - path: /srv/kubernetes/manifests/calico-policy-controller.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: calico-policy-controller
        namespace: calico-system
      spec:
        hostNetwork: true
        containers:
          # The Calico policy controller.
          - name: kube-policy-controller
            image: calico/kube-policy-controller:v0.2.0
            env:
              - name: ETCD_ENDPOINTS
                value: "{{ .ETCDEndpoints }}"
              - name: K8S_API
                value: "http://127.0.0.1:8080"
              - name: LEADER_ELECTION
                value: "true"
          # Leader election container used by the policy controller.
          - name: leader-elector
            image: quay.io/calico/leader-elector:v0.1.0
            imagePullPolicy: IfNotPresent
            args:
              - "--election=calico-policy-election"
              - "--election-namespace=calico-system"
              - "--http=127.0.0.1:4040"
{{ end }}

{{ if .UseCalico }}
  - path: /srv/kubernetes/manifests/calico-system.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "Namespace",
          "metadata": {
            "name": "calico-system"
          }
        }
{{ end }}

  - path: /srv/kubernetes/manifests/kube-dns-rc.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "ReplicationController",
          "metadata": {
            "labels": {
              "k8s-app": "kube-dns",
              "kubernetes.io/cluster-service": "true",
              "version": "v15"
            },
            "name": "kube-dns-v15",
            "namespace": "kube-system"
          },
          "spec": {
            "replicas": 1,
            "selector": {
              "k8s-app": "kube-dns",
              "version": "v15"
            },
            "template": {
              "metadata": {
                "labels": {
                  "k8s-app": "kube-dns",
                  "kubernetes.io/cluster-service": "true",
                  "version": "v15"
                }
              },
              "spec": {
                "containers": [
                  {
                    "args": [
                      "--domain=cluster.local.",
                      "--dns-port=10053"
                    ],
                    "image": "gcr.io/google_containers/kubedns-amd64:1.3",
                    "livenessProbe": {
                      "failureThreshold": 5,
                      "httpGet": {
                        "path": "/healthz",
                        "port": 8080,
                        "scheme": "HTTP"
                      },
                      "initialDelaySeconds": 60,
                      "successThreshold": 1,
                      "timeoutSeconds": 5
                    },
                    "name": "kubedns",
                    "ports": [
                      {
                        "containerPort": 10053,
                        "name": "dns-local",
                        "protocol": "UDP"
                      },
                      {
                        "containerPort": 10053,
                        "name": "dns-tcp-local",
                        "protocol": "TCP"
                      }
                    ],
                    "readinessProbe": {
                      "httpGet": {
                        "path": "/readiness",
                        "port": 8081,
                        "scheme": "HTTP"
                      },
                      "initialDelaySeconds": 30,
                      "timeoutSeconds": 5
                    },
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "200Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "50Mi"
                      }
                    }
                  },
                  {
                    "args": [
                      "--cache-size=1000",
                      "--no-resolv",
                      "--server=127.0.0.1#10053"
                    ],
                    "image": "gcr.io/google_containers/kube-dnsmasq-amd64:1.3",
                    "name": "dnsmasq",
                    "ports": [
                      {
                        "containerPort": 53,
                        "name": "dns",
                        "protocol": "UDP"
                      },
                      {
                        "containerPort": 53,
                        "name": "dns-tcp",
                        "protocol": "TCP"
                      }
                    ]
                  },
                  {
                    "args": [
                      "-cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null",
                      "-port=8080",
                      "-quiet"
                    ],
                    "image": "gcr.io/google_containers/exechealthz-amd64:1.0",
                    "name": "healthz",
                    "ports": [
                      {
                        "containerPort": 8080,
                        "protocol": "TCP"
                      }
                    ],
                    "resources": {
                      "limits": {
                        "cpu": "10m",
                        "memory": "20Mi"
                      },
                      "requests": {
                        "cpu": "10m",
                        "memory": "20Mi"
                      }
                    }
                  }
                ],
                "dnsPolicy": "Default"
              }
            }
          }
        }

  - path: /srv/kubernetes/manifests/kube-dns-svc.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "Service",
          "metadata": {
            "labels": {
              "k8s-app": "kube-dns",
              "kubernetes.io/cluster-service": "true",
              "kubernetes.io/name": "KubeDNS"
            },
            "name": "kube-dns",
            "namespace": "kube-system"
          },
          "spec": {
            "clusterIP": "{{.DNSServiceIP}}",
            "ports": [
              {
                "name": "dns",
                "port": 53,
                "protocol": "UDP"
              },
              {
                "name": "dns-tcp",
                "port": 53,
                "protocol": "TCP"
              }
            ],
            "selector": {
              "k8s-app": "kube-dns"
            }
          }
        }

  - path: /srv/kubernetes/manifests/heapster-de.json
    content: |
        {
          "apiVersion": "extensions/v1beta1",
          "kind": "Deployment",
          "metadata": {
            "labels": {
              "k8s-app": "heapster",
              "kubernetes.io/cluster-service": "true",
              "version": "v1.1.0"
            },
            "name": "heapster-v1.1.0",
            "namespace": "kube-system"
          },
          "spec": {
            "replicas": 1,
            "selector": {
              "matchLabels": {
                "k8s-app": "heapster",
                "version": "v1.1.0"
              }
            },
            "template": {
              "metadata": {
                "labels": {
                  "k8s-app": "heapster",
                  "version": "v1.1.0"
                }
              },
              "spec": {
                "containers": [
                  {
                    "command": [
                      "/heapster",
                      "--source=kubernetes.summary_api:''"
                    ],
                    "image": "gcr.io/google_containers/heapster:v1.1.0",
                    "name": "heapster",
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "200Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "200Mi"
                      }
                    }
                  },
                  {
                    "command": [
                      "/pod_nanny",
                      "--cpu=100m",
                      "--extra-cpu=0.5m",
                      "--memory=200Mi",
                      "--extra-memory=4Mi",
                      "--threshold=5",
                      "--deployment=heapster-v1.1.0",
                      "--container=heapster",
                      "--poll-period=300000",
                      "--estimator=exponential"
                    ],
                    "env": [
                      {
                        "name": "MY_POD_NAME",
                        "valueFrom": {
                          "fieldRef": {
                            "fieldPath": "metadata.name"
                          }
                        }
                      },
                      {
                        "name": "MY_POD_NAMESPACE",
                        "valueFrom": {
                          "fieldRef": {
                            "fieldPath": "metadata.namespace"
                          }
                        }
                      }
                    ],
                    "image": "gcr.io/google_containers/addon-resizer:1.3",
                    "name": "heapster-nanny",
                    "resources": {
                      "limits": {
                        "cpu": "50m",
                        "memory": "100Mi"
                      },
                      "requests": {
                        "cpu": "50m",
                        "memory": "100Mi"
                      }
                    }
                  }
                ]
              }
            }
          }
        }

  - path: /srv/kubernetes/manifests/heapster-svc.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "Service",
          "metadata": {
            "labels": {
              "kubernetes.io/cluster-service": "true",
              "kubernetes.io/name": "Heapster"
            },
            "name": "heapster",
            "namespace": "kube-system"
          },
          "spec": {
            "ports": [
              {
                "port": 80,
                "targetPort": 8082
              }
            ],
            "selector": {
              "k8s-app": "heapster"
            }
          }
        }

  - path: /srv/kubernetes/manifests/kube-dashboard-rc.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "ReplicationController",
          "metadata": {
            "labels": {
              "k8s-app": "kubernetes-dashboard",
              "kubernetes.io/cluster-service": "true",
              "version": "v1.1.0"
            },
            "name": "kubernetes-dashboard-v1.1.0",
            "namespace": "kube-system"
          },
          "spec": {
            "replicas": 1,
            "selector": {
              "k8s-app": "kubernetes-dashboard"
            },
            "template": {
              "metadata": {
                "labels": {
                  "k8s-app": "kubernetes-dashboard",
                  "kubernetes.io/cluster-service": "true",
                  "version": "v1.1.0"
                }
              },
              "spec": {
                "containers": [
                  {
                    "image": "gcr.io/google_containers/kubernetes-dashboard-amd64:v1.1.0",
                    "livenessProbe": {
                      "httpGet": {
                        "path": "/",
                        "port": 9090
                      },
                      "initialDelaySeconds": 30,
                      "timeoutSeconds": 30
                    },
                    "name": "kubernetes-dashboard",
                    "ports": [
                      {
                        "containerPort": 9090
                      }
                    ],
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "50Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "50Mi"
                      }
                    }
                  }
                ]
              }
            }
          }
        }

  - path: /srv/kubernetes/manifests/kube-dashboard-svc.json
    content: |
        {
            "apiVersion": "v1",
            "kind": "Service",
            "metadata": {
                "labels": {
                    "k8s-app": "kubernetes-dashboard",
                    "kubernetes.io/cluster-service": "true"
                },
                "name": "kubernetes-dashboard",
                "namespace": "kube-system"
            },
            "spec": {
                "ports": [
                    {
                        "port": 80,
                        "targetPort": 9090
                    }
                ],
                "selector": {
                    "k8s-app": "kubernetes-dashboard"
                }
            }
        }

  - path: /etc/kubernetes/ssl/ca.pem.enc
    encoding: gzip+base64
    content: {{.TLSConfig.CACert}}

  - path: /etc/kubernetes/ssl/apiserver.pem.enc
    encoding: gzip+base64
    content: {{.TLSConfig.APIServerCert}}

  - path: /etc/kubernetes/ssl/apiserver-key.pem.enc
    encoding: gzip+base64
    content: {{.TLSConfig.APIServerKey}}

{{ if .UseCalico }}
  - path: /etc/kubernetes/cni/net.d/10-calico.conf
    content: |
        {
            "name": "calico",
            "type": "flannel",
            "delegate": {
                "type": "calico",
                "etcd_endpoints": "{{ .ETCDEndpoints }}",
                "log_level": "none",
                "log_level_stderr": "info",
                "hostname": "$private_ipv4",
                "policy": {
                    "type": "k8s",
                    "k8s_api_root": "http://127.0.0.1:8080/api/v1/"
                }
            }
        }
{{ end }}
